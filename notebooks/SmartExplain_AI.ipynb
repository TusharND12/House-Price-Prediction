{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SmartExplain AI ‚Äì Interpretable & Adaptive House Price Prediction Engine\n",
        "\n",
        "## 1Ô∏è‚É£ Title & Abstract\n",
        "\n",
        "**SmartExplain AI** is a production-level ML system combining gradient-descent linear regression with explainability and what-if simulation for house price prediction.\n",
        "\n",
        "**Abstract:** We implement linear regression from scratch using batch, mini-batch, and SGD with L2 regularization. The system provides transparent predictions via per-feature contributions and supports what-if analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2Ô∏è‚É£ Problem Statement\n",
        "\n",
        "Predict median house values in California using census data. We require:\n",
        "- Interpretable predictions (feature contributions)\n",
        "- Flexible optimization (batch/minibatch/SGD, momentum, LR decay)\n",
        "- Reproducible pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3Ô∏è‚É£ Mathematical Formulation\n",
        "\n",
        "**Linear model:**\n",
        "$$y = Xw + b$$\n",
        "\n",
        "**Cost Function (L2 regularized):**\n",
        "$$J(w,b) = \\frac{1}{2m} \\sum_{i=1}^{m} (y_{pred}^{(i)} - y^{(i)})^2 + \\lambda \\sum_{j} w_j^2$$\n",
        "\n",
        "**Gradient Updates:**\n",
        "$$\\frac{\\partial J}{\\partial w} = \\frac{1}{m} X^T (y_{pred} - y) + 2\\lambda w$$\n",
        "$$\\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i} (y_{pred}^{(i)} - y^{(i)})$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "C extension: pandas.util not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext' to build the C extensions first.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[1;32mt:\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\pandas\\__init__.py:39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     40\u001b[0m         is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev,  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     )\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _err:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
            "File \u001b[1;32mt:\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\pandas\\compat\\__init__.py:26\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressors\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     pa_version_under10p1,\n\u001b[0;32m     29\u001b[0m     pa_version_under11p0,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     pa_version_under17p0,\n\u001b[0;32m     35\u001b[0m )\n",
            "File \u001b[1;32mt:\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\pandas\\compat\\numpy\\__init__.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# numpy versioning\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas.util'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m RANDOM_STATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m\n",
            "File \u001b[1;32mt:\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\pandas\\__init__.py:44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _err:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     _module \u001b[38;5;241m=\u001b[39m _err\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC extension: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_module\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not built. If you want to import \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas from the source directory, you may need to run \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython setup.py build_ext\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to build the C extensions first.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     48\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_err\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     51\u001b[0m     get_option,\n\u001b[0;32m     52\u001b[0m     set_option,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m     options,\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n",
            "\u001b[1;31mImportError\u001b[0m: C extension: pandas.util not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext' to build the C extensions first."
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '..')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4Ô∏è‚É£ Data Loading & EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('../data/housing.csv')\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['ocean_proximity'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5Ô∏è‚É£ Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from core.feature_engineering import FeatureEngineer\n",
        "\n",
        "fe = FeatureEngineer(random_state=RANDOM_STATE, use_log_transform=True, cap_outliers=True)\n",
        "X, y = fe.fit_transform(df, target_col='median_house_value')\n",
        "feature_names = fe.get_feature_names()\n",
        "print('Features:', feature_names)\n",
        "print('X shape:', X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6Ô∏è‚É£ Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from core.model import LinearRegressionGD\n",
        "\n",
        "model = LinearRegressionGD(\n",
        "    learning_rate=0.05,\n",
        "    n_iterations=3000,\n",
        "    regularization=0.008,\n",
        "    mode='batch',\n",
        "    use_momentum=True,\n",
        "    momentum=0.9,\n",
        "    use_lr_decay=True,\n",
        "    decay_type='time',\n",
        "    early_stopping=True,\n",
        "    patience=150,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "model.fit(X, y, feature_names=feature_names)\n",
        "y_pred = model.predict(X)\n",
        "print('Weights shape:', model.weights.shape)\n",
        "print('Bias:', model.bias)\n",
        "\n",
        "from visualization.plots import plot_cost_vs_iterations, plot_actual_vs_predicted\n",
        "plot_cost_vs_iterations(model.cost_history)\n",
        "plt.show()\n",
        "plot_actual_vs_predicted(y[:2000], y_pred[:2000])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7Ô∏è‚É£ Optimization Variants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from visualization.plots import plot_optimizer_comparison\n",
        "\n",
        "histories = {}\n",
        "for mode, name in [('batch','Batch GD'), ('minibatch','Mini-batch GD'), ('sgd','SGD')]:\n",
        "    m = LinearRegressionGD(learning_rate=0.01, n_iterations=200, batch_size=64 if mode=='minibatch' else None,\n",
        "                          mode=mode, random_state=RANDOM_STATE)\n",
        "    m.fit(X[:5000], y[:5000], feature_names=feature_names)\n",
        "    histories[name] = m.cost_history\n",
        "\n",
        "plot_optimizer_comparison(histories)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr_histories = {}\n",
        "for lr, name in [(0.01,'lr=0.01'), (0.1,'lr=0.1'), (0.5,'lr=0.5')]:\n",
        "    m = LinearRegressionGD(learning_rate=lr, n_iterations=200, random_state=RANDOM_STATE)\n",
        "    m.fit(X[:3000], y[:3000], feature_names=feature_names)\n",
        "    lr_histories[name] = m.cost_history\n",
        "\n",
        "from visualization.plots import plot_learning_rate_comparison\n",
        "plot_learning_rate_comparison(lr_histories)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8Ô∏è‚É£ Explainability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from core.explainability import FeatureExplainer\n",
        "\n",
        "explainer = FeatureExplainer(model.weights, model.bias, feature_names)\n",
        "result = explainer.explain(X[:1], index=0)\n",
        "print('Total predicted price:', result['total_prediction'][0])\n",
        "print('Contributions:', list(zip(result['feature_names'], result['contributions'][0].round(2))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9Ô∏è‚É£ 3D Cost Surface Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from visualization.cost_surface import plot_cost_surface_3d, get_gradient_descent_path\n",
        "\n",
        "Xs, ys = X[:1000], y[:1000]\n",
        "path = get_gradient_descent_path(Xs, ys, 0, 1, n_steps=15, lr=0.5)\n",
        "fig = plot_cost_surface_3d(Xs, ys, weight_idx1=0, weight_idx2=1, path=path)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîü Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from core.metrics import mae, mse, rmse, r2_score\n",
        "\n",
        "print('MAE:', mae(y, y_pred))\n",
        "print('MSE:', mse(y, y_pred))\n",
        "print('RMSE:', rmse(y, y_pred))\n",
        "print('R2:', r2_score(y, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£1Ô∏è‚É£ Comparison With Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression as SklearnLR\n",
        "\n",
        "sk_model = SklearnLR()\n",
        "sk_model.fit(X, y)\n",
        "sk_pred = sk_model.predict(X)\n",
        "\n",
        "print('Sklearn R2:', r2_score(y, sk_pred))\n",
        "print('Our GD R2:', r2_score(y, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£2Ô∏è‚É£ Conclusion & Future Work\n",
        "\n",
        "We built SmartExplain AI with gradient-descent linear regression, feature engineering, explainability, and optimization variants. Future work: neural networks, tree-based models, uncertainty quantification."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tensorflow_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
